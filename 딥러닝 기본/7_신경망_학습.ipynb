{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7 신경망 학습",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0936c5ed90fa43fdbd8e018652a6a642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edfb81ac189640b1bf79e4bae3b739de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9f57b70ed0d41d58a0dec8241e5153e",
              "IPY_MODEL_e823aa978b52412a9493af4212190910",
              "IPY_MODEL_8fdc1b20d53e4e3bbfbc7fb2fc9e726d"
            ]
          }
        },
        "edfb81ac189640b1bf79e4bae3b739de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9f57b70ed0d41d58a0dec8241e5153e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47224fe1eca44d7fbdadf0473f4a3379",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f4850c114484fc595f91486f1ccf59a"
          }
        },
        "e823aa978b52412a9493af4212190910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_30979cf2787d45849aa2f4c3484e2a97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0a03697df2740f689695543df6ed304"
          }
        },
        "8fdc1b20d53e4e3bbfbc7fb2fc9e726d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bd8a3b02d3e4762882d40f5b37cecfb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c737f5cf89004478a04262d5afe43853"
          }
        },
        "47224fe1eca44d7fbdadf0473f4a3379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f4850c114484fc595f91486f1ccf59a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30979cf2787d45849aa2f4c3484e2a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0a03697df2740f689695543df6ed304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bd8a3b02d3e4762882d40f5b37cecfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c737f5cf89004478a04262d5afe43853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helookscool/DEEP_Learning_Machine_129/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8/7_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyjyu4FzUAVw"
      },
      "source": [
        "# 신경망 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQvNez4qydhL"
      },
      "source": [
        "## 단순한 신경망 구현 : Logic Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7te43hqyiiJ"
      },
      "source": [
        "### 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf2F_YbdybBE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orUoPmDcymhj"
      },
      "source": [
        "### 하이퍼 파라미터(Hyper Parameter)\n",
        "사용자로부터 지정되고 이미 보델 학습전에 지정되서 상수화되어 있는게 보통이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOAmMxo0ymDF"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 0.2 #학습률임\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjmLWgFVysnq"
      },
      "source": [
        "### 유틸 함수들(Util Functions)\n",
        "필요한 함수들을 직접 만들어서 써보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OMFGrjyq1c"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "  return 0.5 * (np.sum((true_y - pred_y)**2))\n",
        "\n",
        "def MSE(y, pred_y): #뭔 MSE코드오류라는데 위의 코드가 틀린듯. 근데 강의는 그냥 진행됨.\n",
        "  return np.mean(np.sum(np.square((y - pred_y))))\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = pred_y.reshape(1, -1)\n",
        "\n",
        "  delta = 1e-7\n",
        "  return -np.sum(true_y * np.log(pred_y + dleta))\n",
        "  #로그함수에 0대입하면 무한대로 가버리니까, -무한대로 가지 않게 하는 아주 작은 델타값을 더해준다. \n",
        "\n",
        "def cross_entropy_error_for_batch(pred_y, true_y):#벳치의 경우 상정. \n",
        "#벳치사이즈로 구분해서 계산하다보면 베치 사이즈로 각 값들을 나눠줘야한다.\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = pred_y.reshape(1, -1)\n",
        "\n",
        "  delta = 1e-7\n",
        "  batch_size = pred_y.shape[0]\n",
        "  return -np.sum(true_y * np.log(pred_y + dleta)) / batch_size \n",
        "\n",
        "def cross_entropy_error_for_bin(pred_y, true_y):\n",
        "  return 0.5 * np.sum((-true_y * np.log(pred_y) - (1- true_y) * np.log(1-pred_y)))\n",
        "\n",
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "\n",
        "  return y\n",
        "\n",
        "def diffrential(f, x):\n",
        "  eps = 1e-5 #작은 앱실론 값을 주고...\n",
        "  diff_value = np.zeros_like(x) #크기는 x인데 내용물을 0으로 채운 배열하나 만들어주고...\n",
        "\n",
        "  for i in range(x.shape[0]):\n",
        "    temp_val = x[i]\n",
        "    \n",
        "    x[i] = temp_val + eps\n",
        "    f_h1 = f(x)\n",
        "\n",
        "    x[i] = temp_val - eps\n",
        "    f_h2 = f(x)\n",
        "\n",
        "    diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "    x[i] = temp_val\n",
        "\n",
        "  return diff_value"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Z2LTT_y3i5"
      },
      "source": [
        "### 신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMTjjYgdy3D8"
      },
      "source": [
        "class LogicGateNet():\n",
        "\n",
        "  def __init__(self):\n",
        "    def weight_init():\n",
        "      np.random.seed(1)\n",
        "      #가중치, 바이어스 다 초기화 해줘야됨.\n",
        "      weights = np.random.randn(2)\n",
        "      bias = np.random.rand(1)\n",
        "\n",
        "      return weights, bias\n",
        "\n",
        "    self.weights, self.bias = weight_init() #여기까지가 초기화 과정임.\n",
        "\n",
        "  def predict(self, x):\n",
        "    W = self.weights.reshape(-1, 1)\n",
        "    b = self.bias\n",
        "\n",
        "    pred_y = sigmoid(np.dot(x, W) + b)#활성화 함수\n",
        "    return pred_y\n",
        "\n",
        "  def loss(self, x, true_y): #손실함수\n",
        "    pred_y = self.predict(x)\n",
        "    return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "\n",
        "  def get_gradient(self, x, t): #그레디언트 값을 구한다는데?\n",
        "    def loss_grad(grad):\n",
        "      return self.loss(x, t)\n",
        "\n",
        "  #그레디언트를 다 반영하기 위해서 loss값에다 그레디언트를 반영하는 과정?\n",
        "    grad_W = diffrential(loss_grad, self.weights)\n",
        "    grad_B = diffrential(loss_grad, self.bias)\n",
        "\n",
        "    return grad_W, grad_B"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNDoH_3zbGZ"
      },
      "source": [
        "### AND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P-ib8_RzHTh"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRiaACA6zGom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4196e50-f61d-4096-f669-1a91421274f7"
      },
      "source": [
        "#AND게이트는 둘다 1 일때만 1이다. \n",
        "AND = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = AND.get_gradient(X,Y)\n",
        "\n",
        "  AND.weights -= lr * grad_W\n",
        "  AND.bias -= lr * grad_B\n",
        "\n",
        "  loss = AND.loss(X, Y)\n",
        "  train_loss_list.append(loss) #현재 LOSS값이 몇인지 리스트에 저장해줌\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, AND.weights, AND.bias))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.49396867843617975, Weights: [2.01503856 1.71662117], Bias: [-3.08282757]\n",
            "Epoch: 200, Cost: 0.3253343795271425, Weights: [2.79693855 2.73539701], Bias: [-4.37630256]\n",
            "Epoch: 300, Cost: 0.24302342001811633, Weights: [3.40228815 3.3848267 ], Bias: [-5.29773137]\n",
            "Epoch: 400, Cost: 0.19344240185905218, Weights: [3.8824553  3.87626796], Bias: [-6.01648561]\n",
            "Epoch: 500, Cost: 0.16029457035245787, Weights: [4.27734849 4.27477562], Bias: [-6.60554348]\n",
            "Epoch: 600, Cost: 0.13661422486224933, Weights: [4.61168928 4.6104836 ], Bias: [-7.10408809]\n",
            "Epoch: 700, Cost: 0.11888494243349108, Weights: [4.9011229  4.90050339], Bias: [-7.5358348]\n",
            "Epoch: 800, Cost: 0.10513498469279867, Weights: [5.15603123 5.15568883], Bias: [-7.91628056]\n",
            "Epoch: 900, Cost: 0.09417321088544701, Weights: [5.38361567 5.38341492], Bias: [-8.25611777]\n",
            "Epoch: 1000, Cost: 0.08523824303938289, Weights: [5.58906188 5.58893832], Bias: [-8.56303389]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoyQv_czT7R"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7CvWgc9zREa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0841062-33e4-45bb-c7ec-46a544235c99"
      },
      "source": [
        "print(AND.predict(X))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.91002335e-04]\n",
            " [4.86099648e-02]\n",
            " [4.86156795e-02]\n",
            " [9.31818598e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMXNiXWzts-"
      },
      "source": [
        "### OR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ79pc4jzw3O"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gnLmAyQzuoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f3825d-3d9e-44c5-e946-31ff8546f3f4"
      },
      "source": [
        "OR = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_2 = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = OR.get_gradient(X,Y_2)\n",
        "\n",
        "  OR.weights -= lr * grad_W\n",
        "  OR.bias -= lr * grad_B\n",
        "\n",
        "  loss = OR.loss(X, Y_2)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, OR.weights, OR.bias))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.3393288167819607, Weights: [2.98831871 2.39880239], Bias: [-0.67875835]\n",
            "Epoch: 200, Cost: 0.2060032953656718, Weights: [3.85457519 3.61235159], Bias: [-1.30773792]\n",
            "Epoch: 300, Cost: 0.14646151032997104, Weights: [4.51092321 4.38480447], Bias: [-1.70090032]\n",
            "Epoch: 400, Cost: 0.1129747092174115, Weights: [5.02588551 4.94993214], Bias: [-1.98818437]\n",
            "Epoch: 500, Cost: 0.09165264913456045, Weights: [5.44543336 5.39513131], Bias: [-2.21445381]\n",
            "Epoch: 600, Cost: 0.07695035178050828, Weights: [5.79774684 5.76215647], Bias: [-2.40088812]\n",
            "Epoch: 700, Cost: 0.0662299812387976, Weights: [6.10062111 6.0741922 ], Bias: [-2.55926578]\n",
            "Epoch: 800, Cost: 0.05808247762977344, Weights: [6.3658123  6.34545117], Bias: [-2.69682842]\n",
            "Epoch: 900, Cost: 0.051689427544127094, Weights: [6.60142242 6.58527659], Bias: [-2.81834678]\n",
            "Epoch: 1000, Cost: 0.04654419034600559, Weights: [6.81324253 6.80013851], Bias: [-2.9271287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWmEtX_VnLSI"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPpOs3-z2vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5868172-ca6f-4726-927c-068bc3aa63fc"
      },
      "source": [
        "print(OR.predict(X))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05082867]\n",
            " [0.97962797]\n",
            " [0.97988785]\n",
            " [0.99997714]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEBhczCIz57Q"
      },
      "source": [
        "### NAND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzQaaHKKz8sZ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h463QUQRz8PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e091e5ed-d9cd-4f0a-92c2-5e9c5b3703df"
      },
      "source": [
        "NAND = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_3 = np.array([[1], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = NAND.get_gradient(X,Y_3)\n",
        "\n",
        "  NAND.weights -= lr * grad_W\n",
        "  NAND.bias -= lr * grad_B\n",
        "\n",
        "  loss = NAND.loss(X, Y_3)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, NAND.weights, NAND.bias))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 0.5421738801873841, Weights: [-1.52038477 -1.8044596 ], Bias: [2.79613861]\n",
            "Epoch: 200, Cost: 0.34513921235779443, Weights: [-2.61076184 -2.66551134], Bias: [4.18950611]\n",
            "Epoch: 300, Cost: 0.25403140982901523, Weights: [-3.29126404 -3.30609336], Bias: [5.15778594]\n",
            "Epoch: 400, Cost: 0.20045713974610346, Weights: [-3.80128706 -3.80637256], Bias: [5.90451903]\n",
            "Epoch: 500, Cost: 0.1651450652487038, Weights: [-4.21231761 -4.21438224], Bias: [6.51232147]\n",
            "Epoch: 600, Cost: 0.14016009838329124, Weights: [-4.55704426 -4.55799437], Bias: [7.02432061]\n",
            "Epoch: 700, Cost: 0.12158500289548078, Weights: [-4.85385997 -4.85434129], Bias: [7.46619134]\n",
            "Epoch: 800, Cost: 0.10725643533767862, Weights: [-5.11434269 -5.11460572], Bias: [7.85452518]\n",
            "Epoch: 900, Cost: 0.09588204504011677, Weights: [-5.34630895 -5.34646174], Bias: [8.20067666]\n",
            "Epoch: 1000, Cost: 0.08664288534732459, Weights: [-5.55529987 -5.55539319], Bias: [8.51275788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR-rHaTU0Mga"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpzKW6sm0Ghp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcfc35d-0c50-4ea6-aa03-06b2bf6e0176"
      },
      "source": [
        "print(NAND.predict(X))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99979915]\n",
            " [0.95061041]\n",
            " [0.95061479]\n",
            " [0.06927143]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTWfSQ60Zl2"
      },
      "source": [
        "### XOR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmmL0VIu0bXq"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CGm0r1M0a9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5668c5c-f462-4011-853a-38c9ad48f286"
      },
      "source": [
        "XOR = LogicGateNet()\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_4 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grad_W, grad_B = XOR.get_gradient(X,Y_4)\n",
        "\n",
        "  XOR.weights -= lr * grad_W\n",
        "  XOR.bias -= lr * grad_B\n",
        "\n",
        "  loss = XOR.loss(X, Y_4)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, XOR.weights, XOR.bias))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 1.3879051497872243, Weights: [ 0.15549717 -0.03283867], Bias: [-0.0727685]\n",
            "Epoch: 200, Cost: 1.3863226443982282, Weights: [0.0201055  0.00512345], Bias: [-0.01496259]\n",
            "Epoch: 300, Cost: 1.3862953047043771, Weights: [0.00318944 0.0019981 ], Bias: [-0.00307658]\n",
            "Epoch: 400, Cost: 1.3862943994183752, Weights: [0.00058069 0.00048596], Bias: [-0.0006326]\n",
            "Epoch: 500, Cost: 1.3862943627290027, Weights: [0.00011343 0.00010589], Bias: [-0.00013007]\n",
            "Epoch: 600, Cost: 1.3862943611878575, Weights: [2.28475138e-05 2.22485217e-05], Bias: [-2.67451317e-05]\n",
            "Epoch: 700, Cost: 1.3862943611227636, Weights: [4.66005340e-06 4.61244465e-06], Bias: [-5.49924444e-06]\n",
            "Epoch: 800, Cost: 1.386294361120012, Weights: [9.55179217e-07 9.51397629e-07], Bias: [-1.13073444e-06]\n",
            "Epoch: 900, Cost: 1.386294361119896, Weights: [1.96161924e-07 1.95857555e-07], Bias: [-2.32499625e-07]\n",
            "Epoch: 1000, Cost: 1.3862943611198908, Weights: [4.03088158e-08 4.03042065e-08], Bias: [-4.78073636e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-ktElI0o5P"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWAJAJ_T0oqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be6157f-bfc2-4e50-f5a0-1f42529989b0"
      },
      "source": [
        "print(XOR.predict(X))\n",
        "#XOR문제가 발생하여 학습이 잘 안됨. XOR은 다층 신경망 구조로 구현해야함. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49999999]\n",
            " [0.5       ]\n",
            " [0.5       ]\n",
            " [0.50000001]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlq_-6E1nIq"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(1)\n",
        "\n",
        "- 얕은 신경망, Shallow Neural Network\n",
        "\n",
        "- 두 논리게이트(NAND, OR)를 통과하고  \n",
        "  AND 게이트로 합쳐서 구현\n",
        "\n",
        "- 06 신경망 구조 참고"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr7nYMG20jTo"
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "s1 = NAND.predict(X)\n",
        "s2 = OR.predict(X)\n",
        "X_2 = np.array([s1, s2]).T.reshape(-1, 2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTDx8Ah1xHY"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2iD5A91yWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6a39a9-84c3-4b75-d963-3f507b858d75"
      },
      "source": [
        "print(AND.predict(X_2)) #결과값이 0 ,1, 1, 0 정답을 맞출 확률에 가까워지고 있다. "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.06350555]\n",
            " [0.90247804]\n",
            " [0.90260795]\n",
            " [0.06997581]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-SK4G262Agn"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(2)\n",
        "- 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpnHCRZ1zwr"
      },
      "source": [
        "class XORNet():\n",
        "\n",
        "  def __init__(self):\n",
        "    np.random.seed(1)\n",
        "\n",
        "    def weight_init():\n",
        "      params = {}\n",
        "      params['w_1'] = np.random.randn(2)\n",
        "      params['b_1'] = np.random.rand(2)\n",
        "      params['w_2'] = np.random.randn(2)\n",
        "      params['b_2'] = np.random.rand(1)\n",
        "      return params\n",
        "\n",
        "    self.params = weight_init()\n",
        "\n",
        "  def predict(self, x):\n",
        "    W_1, W_2 = self.params['w_1'].reshape(-1, 1), self.params['w_2'].reshape(-1,1)\n",
        "    B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
        "\n",
        "    A1 = np.dot(x, W_1) + B_1\n",
        "    Z1 = sigmoid(A1)\n",
        "    A2 = np.dot(Z1, W_2) + B_2\n",
        "    pred_y = sigmoid(A2)\n",
        "\n",
        "    return pred_y\n",
        "\n",
        "  def loss(self, x, true_y):\n",
        "    pred_y = self.predict(x)\n",
        "    return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "\n",
        "  def get_gradient(self, x, t):\n",
        "    def loss_grad(grad):\n",
        "      return self.loss(x,t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['w_1'] = diffrential(loss_grad, self.params['w_1'])\n",
        "    grads['b_1'] = diffrential(loss_grad, self.params['b_1'])\n",
        "    grads['w_2'] = diffrential(loss_grad, self.params['w_2'])\n",
        "    grads['b_2'] = diffrential(loss_grad, self.params['b_2'])\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lplK_x0l2YLh"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)\n",
        "- 재조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf-3wWSv2b7l"
      },
      "source": [
        "lr = 0.3"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHKd45d2JbJ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQNd3XVd2Gj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93506316-9482-4e14-e5d9-479212ddf1d3"
      },
      "source": [
        "XOR = XORNet()\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "train_loss_list = list()\n",
        "\n",
        "for i in range(epochs):\n",
        "  grads = XOR.get_gradient(X, Y_5)\n",
        "\n",
        "  for key in ('w_1', 'b_1', 'w_2', 'b_2'):\n",
        "    XOR.params[key] -= lr * grads[key]\n",
        "  \n",
        "\n",
        "  loss = XOR.loss(X, Y_5)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"Epoch: {}, Cost: {}\".format(i+1, loss))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Cost: 1.353561444245376\n",
            "Epoch: 200, Cost: 1.2827154568291983\n",
            "Epoch: 300, Cost: 0.8968907892231803\n",
            "Epoch: 400, Cost: 0.338719714121707\n",
            "Epoch: 500, Cost: 0.18121344476204979\n",
            "Epoch: 600, Cost: 0.11991186457349581\n",
            "Epoch: 700, Cost: 0.08861936864730534\n",
            "Epoch: 800, Cost: 0.0699218065308316\n",
            "Epoch: 900, Cost: 0.05758041353096763\n",
            "Epoch: 1000, Cost: 0.0488609356844432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIV_GsoG2eDs"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpr0nZhc2Szr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a2e127-7330-4efb-aaa6-ee3c517515a3"
      },
      "source": [
        "print(XOR.predict(X))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0217367 ]\n",
            " [0.96884394]\n",
            " [0.97816819]\n",
            " [0.0217794 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1IuDL8R7wrx"
      },
      "source": [
        "## 다중 클래스 분류 : MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CiJ5Gmq9Wpa"
      },
      "source": [
        "### 배치 처리\n",
        "- 학습 데이터 전체를 한번에 진행하지 않고  \n",
        "  일부 데이터(샘플)을 확률적으로 구해서 조금씩 나누어 진행\n",
        "\n",
        "- 확률적 경사 하강법(Stochastic Gradient Descent) 또는  \n",
        "  미니 배치 학습법(mini-batch learning)이라고도 부름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUDNWwj49byH"
      },
      "source": [
        "#### 신경망 구현 : MNIST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjBRQYlP74GM"
      },
      "source": [
        "#### 필요한 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0lJbkuW71lm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDvtEiD77_gu"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WL7zXMl_uo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345448b6-2c0e-4854-eeab-75fe37dcac4c"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
        "#이렇게 바로 스플릿 되는거임?"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_rNg5Jn8FRA"
      },
      "source": [
        "#### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4wpsQGA8BOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937c2226-f782-48c5-88fd-91b6caaa14c8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7nvkHO8IFR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "e56b7534-ec40-4022-e571-9ddf104447ac"
      },
      "source": [
        "img = x_train[0]\n",
        "print(img.shape)\n",
        "\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbBA1Kl18KGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213ed00e-5370-4254-d576-8859f04458ad"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTFu8i-z8U_C"
      },
      "source": [
        "#### 데이터 전처리 (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76pjKDVftHJ"
      },
      "source": [
        "def flatten_for_mnist(x):\n",
        "  temp = np.zeros((x.shape[0], x[0].size))\n",
        "\n",
        "  for idx, data in enumerate(x):\n",
        "    temp[idx, :] = data.flatten()\n",
        "  \n",
        "  return temp"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvMWrDOR8Mns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9464126-857e-474c-a88a-25eeda869496"
      },
      "source": [
        "#normalization해주자.정규화\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = flatten_for_mnist(x_train)\n",
        "x_test = flatten_for_mnist(x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "#텐서플로에도 원핫인코딩있음.\n",
        "y_train_ohe = tf.one_hot(y_train, depth=10).numpy()\n",
        "y_test_ohe = tf.one_hot(y_test, depth=10).numpy()\n",
        "\n",
        "print(y_train_ohe.shape)\n",
        "print(y_test_ohe.shape)\n",
        "\n",
        "#flatten으로 펴줬기 때문에 shape가 변했다. "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LjpWz0dotJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e5f6b9-293b-48ea-c605-dcfbbaa7410b"
      },
      "source": [
        "print(x_train[0].max(), x_train[0].min()) #자연스럽게 minmax스케일링 했다는데?\n",
        "print(y_train_ohe[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.0\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUaa92Y9RhY"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk3FXXLi9Th5"
      },
      "source": [
        "epochs =2 \n",
        "lr = 0.1\n",
        "batch_size = 100\n",
        "train_size = x_train.shape[0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lMJ0h8p8iZl"
      },
      "source": [
        "#### 사용되는 함수들(Util Functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSlqZ2Xx8hFn"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "  return 0.5 * (np.sum((true_y - pred_y)**2))\n",
        "\n",
        "def MSE(y, pred_y): #뭔 MSE코드오류라는데 위의 코드가 틀린듯. 근데 강의는 그냥 진행됨.\n",
        "  return np.mean(np.sum(np.square((y - pred_y))))\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = pred_y.reshape(1, -1)\n",
        "\n",
        "  delta = 1e-7\n",
        "  return -np.sum(true_y * np.log(pred_y + dleta))\n",
        "  #로그함수에 0대입하면 무한대로 가버리니까, -무한대로 가지 않게 하는 아주 작은 델타값을 더해준다. \n",
        "\n",
        "def cross_entropy_error_for_batch(pred_y, true_y):#벳치의 경우 상정. \n",
        "#벳치사이즈로 구분해서 계산하다보면 베치 사이즈로 각 값들을 나눠줘야한다.\n",
        "  if true_y.ndim == 1:\n",
        "    true_y = true_y.reshape(1, -1)\n",
        "    pred_y = pred_y.reshape(1, -1)\n",
        "\n",
        "  delta = 1e-7\n",
        "  batch_size = pred_y.shape[0]\n",
        "  return -np.sum(true_y * np.log(pred_y + dleta)) / batch_size \n",
        "\n",
        "def cross_entropy_error_for_bin(pred_y, true_y):\n",
        "  return 0.5 * np.sum((-true_y * np.log(pred_y) - (1- true_y) * np.log(1-pred_y)))\n",
        "\n",
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "\n",
        "  return y\n",
        "\n",
        "def diffrential_1d(f, x):\n",
        "  eps = 1e-5 #작은 앱실론 값을 주고...\n",
        "  diff_value = np.zeros_like(x) #크기는 x인데 내용물을 0으로 채운 배열하나 만들어주고...\n",
        "  \n",
        "  for i in range(x.shape[0]):\n",
        "    temp_val = x[i]\n",
        "    \n",
        "    x[i] = temp_val + eps\n",
        "    f_h1 = f(x)\n",
        "\n",
        "    x[i] = temp_val - eps\n",
        "    f_h2 = f(x)\n",
        "\n",
        "    diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "    x[i] = temp_val\n",
        "\n",
        "  return diff_value\n",
        "\n",
        "def diffrential_2d(f, X):    #2차원은 대문자 쓴다는데\n",
        "  if X.ndim == 1:\n",
        "    return diffrential_1d(f,X)\n",
        "  else:\n",
        "    grad = np.zeros_like(X)\n",
        "\n",
        "    for idx, x in enumerate(X):\n",
        "      grad[idx] = differential_1d(f,x)\n",
        "\n",
        "    return grad\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoV9fyj8_u7"
      },
      "source": [
        "#### 2층 신경망으로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBObD5Fw89HI"
      },
      "source": [
        "class MyModel():\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    def weight_init(input_nodes, hidden_nodes, output_units):\n",
        "      np.random.seed(777)\n",
        "\n",
        "      params = {}\n",
        "      params['w_1'] = 0.01 * np.random.randn(input_nodes, hidden_nodes)\n",
        "      params['b_1'] = np.zeros(hidden_nodes)\n",
        "      params['w_2'] = 0.01 * np.random.randn(hidden_nodes, output_units)\n",
        "      params['b_2'] = np.zeros(output_units)\n",
        "\n",
        "      return params\n",
        "\n",
        "    self.params = weight_init(784, 64, 10)\n",
        "\n",
        "  def predict(self, x):\n",
        "    W_1, W_2 = self.params['w_1'], self.params['w_2']\n",
        "    B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
        "\n",
        "    A1 = np.dot(x, W_1) + B_1\n",
        "    Z1 = sigmoid(A1)\n",
        "    \n",
        "    A2 = np.dot(Z1, W_2) + B_2\n",
        "    pred_y = softmax(A2) #다층모델이므로 시그모이드말고 소프트맥스로 한다. \n",
        "\n",
        "    return pred_y\n",
        "\n",
        "  def loss(self, x, true_y):\n",
        "    pred_y = self.predict(x)\n",
        "    return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "\n",
        "  #accuracy값 추가\n",
        "  def accuracy(self, x, true_y):\n",
        "    pred_y = self.predict(x)\n",
        "    y_argmax = np.argmax(pred_y, axis=1)\n",
        "    t_argmax = np.argmax(true_y, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y_argmax == t_argmax) / float(x.shape[0])\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "  def get_gradient(self, x, t):\n",
        "    \n",
        "    def loss_grad(grad):\n",
        "      return self.loss(x,t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['w_1'] = diffrential_2d(loss_grad, self.params['w_1'])\n",
        "    grads['b_1'] = diffrential_2d(loss_grad, self.params['b_1'])\n",
        "    grads['w_2'] = diffrential_2d(loss_grad, self.params['w_2'])\n",
        "    grads['b_2'] = diffrential_2d(loss_grad, self.params['b_2'])\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maKNIlK-xJ5k"
      },
      "source": [
        "#### 모델 생성 및 학습\n",
        "- 시간 많이 소요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSEARgNIop8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "0936c5ed90fa43fdbd8e018652a6a642",
            "edfb81ac189640b1bf79e4bae3b739de",
            "e9f57b70ed0d41d58a0dec8241e5153e",
            "e823aa978b52412a9493af4212190910",
            "8fdc1b20d53e4e3bbfbc7fb2fc9e726d",
            "47224fe1eca44d7fbdadf0473f4a3379",
            "8f4850c114484fc595f91486f1ccf59a",
            "30979cf2787d45849aa2f4c3484e2a97",
            "d0a03697df2740f689695543df6ed304",
            "9bd8a3b02d3e4762882d40f5b37cecfb",
            "c737f5cf89004478a04262d5afe43853"
          ]
        },
        "outputId": "67392c0c-fb11-47a8-f97d-ea026740ea4a"
      },
      "source": [
        "#왜 오류난건지 모르겠음. 나중에 고치자 찌발. \n",
        "\n",
        "model = MyModel\n",
        "train_loss_list = list()\n",
        "train_acc_list = list()\n",
        "test_acc_list = list()\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "start_time = time.time()\n",
        "for i in tqdm(range(epochs)):\n",
        "  batch_idx = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_idx]\n",
        "  y_batch = y_train_ohe[batch_idx]\n",
        "\n",
        "  grads = model.get_gradient(x_batch, y_batch)\n",
        "\n",
        "  #가중치 업데이트\n",
        "  for key in grad.keys():\n",
        "    model.params[key] -= lr * grads[key]\n",
        "\n",
        "  loss = model.loss(x_batch, y_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  train_accuracy = model.accuracy(x_train, y_train_ohe)\n",
        "  test_accuracy = model.accuracy(x_test, y_test_ohe)\n",
        "  train_acc_list.append(train_accuracy)\n",
        "  test_acc_list.append(test_accuracy)\n",
        "\n",
        "  print(\"Epoch: {}, Cost: {}, Train Accuracy: {}, Test Accuracy: {}\".format(i+1, loss, train_accuracy, test_accuracy))\n",
        "\n",
        "  #formatted = f'Epoch: {i+1}, Cost: {loss}, Train Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}'\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"총 학습 소요시간: {:.3f}s\".format(end_time-start_time))\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0936c5ed90fa43fdbd8e018652a6a642",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-0187b28ebf3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_ohe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#가중치 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_gradient() missing 1 required positional argument: 't'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7nL8f20x4zl"
      },
      "source": [
        "### 모델의 결과\n",
        "- 모델은 학습이 잘 될 수도, 잘 안될 수도 있음\n",
        "\n",
        "- 만약, 학습이 잘 되지 않았다면,  \n",
        "  학습이 잘 되기 위해서 어떠한 조치를 취해야 하는가?\n",
        "  - 다양한 학습관련 기술이 존재"
      ]
    }
  ]
}